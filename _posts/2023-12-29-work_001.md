---
layout: post
title:  "Lidar 3d感知算法"
---

# VoxelNet
[code](https://github.com/skyhehe123/VoxelNet-pytorch/tree/master)

![VoxelNet](https://pic3.zhimg.com/80/v2-2e55b709d1ac7b37a3fdf04abe826a2e_720w.webp "VoxelNet网络结构")
- voxelize

输入点云数据: n x 4(x,y,z,intensity)  
感知范围和感知分辨率: [xmin,ymin,zmin,xmax,ymax,zmax], [voxel_size_x, voxel_size_y, voxel_size_z]  
坐标轴前x,左y,上z:  
D = int((xmax-xmin) / voxel_size_x);  
H = int((zmax-zmin) / voxel_size_z);  
W = int((ymax-ymin) / voxel_size_y);  
申请内存:  
float* input = malloc(D x H x W x T(一个voxel最大点数) x 4(channel数) x sizeof(float));
float* inputNum = malloc(D x H x W x sizeof(int));  
对于每个点p,计算index, 则:  
input[index x T x 4 + inputNum[index] x 4] = p;  
inputNum[index]++; (超过T个点就丢掉)  

假如不用VFE，input可直接用于3d卷积。


- SVFE

输入:m x T x 4 特征, m x 3坐标;m是n个点经过voxelsize之后的有效voxel索引。
一个VFE产生m x T x C 特征。
SVFE表示多个VFE 堆积起来。

![VFE](https://pic2.zhimg.com/80/v2-c672c5e095b09499f05dc10ccf57b2c5_720w.webp "")


# MV3D
[code](https://github.com/bostondiditeam/MV3D/tree/master)

![MV3D](https://pic2.zhimg.com/80/v2-5f870476bdcfa090ef772a4b9fb8c225_720w.webp "")

- 点云俯视图生成

输入点云数据: n x 4(x,y,z,intensity)  
感知范围和感知分辨率: [xmin,ymin,zmin,xmax,ymax,zmax], [voxel_size_x, voxel_size_y, voxel_size_z]  
坐标轴前x,左y,上z:  
D = int((xmax-xmin) / voxel_size_x);  
W = int((ymax-ymin) / voxel_size_y);  
H = int((zmax-zmin) / voxel_size_z);  
bev特征由3部分组成
- 高度图: 大小H x D x W,每个voxel_size_z 内,取点云高度最高值  
- 强度图: 大小1 x D x W, 每个bev grid内，最大高度的点云反射强度  
- 密度图: 大小1 x D x W, 每个bev grid内， 统计点云个数N，特征编码为$min(1.0, \frac{log(N+1)}{log64})$



# PointPillars
[code](https://github.com/SmallMunich/nutonomy_pointpillars/tree/master)

![pointpillars网络结构](https://pic2.zhimg.com/80/v2-d15befd8e627a5b087d11ae49f46a7f9_720w.webp "pointpillars网络结构")

- 伪图像点云特征图生成

输入点云数据: n x 4(x,y,z,intensity)  
输出:
- pillar 特征: [M(设定的最大grid数目), max_points(每个pillar里面最多点数), ndim(每个点云数目)]
- 每个grid坐标: [M, 3]
- 每个grid里面里面包含的有效点数: [M]
